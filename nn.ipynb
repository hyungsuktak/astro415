{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "In this R Jupyter notebook, we go through the code implementation for a neural network model. In particular, we are interested in whether the probability of getting $A/A-$ is related to both midterm 1 score and gender.\n",
    "\n",
    "## 1. Loading the data\n",
    "\n",
    "If the data size is not large, it may be convenient to make two data vectors manually as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm1 <- c(23, 22.5, 21.5, 21.25, 13, 25, 14.5, 20, 18, 18, 19.5, \n",
    "              25, 23, 19, 24, 20, 24, 24, 18.5, 18, 16, 21.85, 25, 19.5) # explanatory variable 1\n",
    "\n",
    "gender <- c(0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1) # explanatory variable 2\n",
    "\n",
    "aam <- c(1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0) # response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data size is not small enough for a manual input, we have to load the data. The following is an example of loading the data \"aam.csv\" from my desktop folder. Please refer to the previous jupyter notebooks, especially \"SLR.ipynb\", which contains details of loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>AAm</th><th scope=col>midterm1</th><th scope=col>gender</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>23.00</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>22.50</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td>21.50</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0</td><td>21.25</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0</td><td>13.00</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1</td><td>25.00</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & AAm & midterm1 & gender\\\\\n",
       "  & <int> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 23.00 & 0\\\\\n",
       "\t2 & 1 & 22.50 & 0\\\\\n",
       "\t3 & 1 & 21.50 & 0\\\\\n",
       "\t4 & 0 & 21.25 & 0\\\\\n",
       "\t5 & 0 & 13.00 & 0\\\\\n",
       "\t6 & 1 & 25.00 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | AAm &lt;int&gt; | midterm1 &lt;dbl&gt; | gender &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | 23.00 | 0 |\n",
       "| 2 | 1 | 22.50 | 0 |\n",
       "| 3 | 1 | 21.50 | 0 |\n",
       "| 4 | 0 | 21.25 | 0 |\n",
       "| 5 | 0 | 13.00 | 0 |\n",
       "| 6 | 1 | 25.00 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  AAm midterm1 gender\n",
       "1 1   23.00    0     \n",
       "2 1   22.50    0     \n",
       "3 1   21.50    0     \n",
       "4 0   21.25    0     \n",
       "5 0   13.00    0     \n",
       "6 1   25.00    0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setwd(\"~/Desktop/\")\n",
    "data <- read.csv(\"aam.csv\", header = TRUE) # R is case-sensitive\n",
    "head(data)\n",
    "aam <- data[, 1]\n",
    "midterm1 <- data[, 2]\n",
    "gender <- data[, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Window users, the fist line of the code above is replaced with\n",
    "\n",
    "setwd(\"C:/Users/hyungsuktak/Desktop/\")\n",
    "\n",
    "If the data file is a .txt file, then the following code will be used instead.\n",
    "\n",
    "midterm <- read.table(\"aam.txt\", header = TRUE)\n",
    "\n",
    "To check whether the data are correctly loaded, we use the function \"head\" that shows the first six lines of the data. To avoid any mistake, it is better to check whether the first row is correctly loaded. In this case, the first row correctly starts with (1, 23, 0).\n",
    "\n",
    "Next, we designate each column of the data to an object, as we input manually in the beginning. \n",
    "\n",
    "Now the data are loaded, and we are ready to conduct a multiple linear regression analysis.\n",
    "\n",
    "## 2. Fitting a neural network model\n",
    "\n",
    "We are going to fit and compare a neural network model that has two hidden layers with three and two nodes, respectively.  \n",
    "\n",
    "The Sigmoid activation function will be used at each node. As shown during the class, such a neural network model for a binary classification with the Sigmoid activation function (at least in the last layer) can be considered as a logistic regression model with a complicated link function. In this sense, the response variables ($Y_i$'s) are  independent Bernoulli random variables  with probabilities of getting $A/A-$ equal to $\\theta_i=h_w(x_i)$'s, i.e.,\n",
    "\n",
    "$$\n",
    "Y_i\\stackrel{\\textrm{ind.}}{\\sim} \\textrm{Bern}(h_w(x_i)),\n",
    "$$\n",
    "\n",
    "where $x_i=(1, x_{i1}, x_{i2})^{\\top}$ and $h_w(x_i)$ is the activated value in the last layer for the $i$-th person, ranging between 0 and 1 due to the Sigmoid activation function. This function $h_w(x_i)$ represents the entire connections throughout the neural net with an input $x_i$, so this is a very complicated (but still deterministic) function. The log-likelihood function of this model is\n",
    "\n",
    "$$\n",
    "\\ell(w)= \\sum_{i=1}^n\\left[y_i\\log(h_w(x_i)) + (1-y_i)\\log(1-h_w(x_i))\\right].\n",
    "$$\n",
    "\n",
    "\n",
    "We estimate weights $w$ by the values that maximize the log-likelihood function above, or equivalently the values that minimize the negative log-likelihood function, called a cost function in machine learning.\n",
    "\n",
    "In R, there are many packages to fit neural network models, but here we use \"neuralnet\". To use this package, we need to intall and load it on R as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/yk/fk6w4crd17v4g_qflhhv1xlc0000gn/T//RtmpAxhPxi/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"neuralnet\")\n",
    "library(neuralnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure prediction accuracy, we use a cross-validation by splitting the data set into training and test sets. We randomly select 15 people and assign them to the training set and the rest of people to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>9</li><li>16</li><li>20</li><li>21</li><li>24</li><li>2</li><li>10</li><li>3</li><li>22</li><li>8</li><li>19</li><li>6</li><li>4</li><li>14</li><li>15</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 9\n",
       "\\item 16\n",
       "\\item 20\n",
       "\\item 21\n",
       "\\item 24\n",
       "\\item 2\n",
       "\\item 10\n",
       "\\item 3\n",
       "\\item 22\n",
       "\\item 8\n",
       "\\item 19\n",
       "\\item 6\n",
       "\\item 4\n",
       "\\item 14\n",
       "\\item 15\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 9\n",
       "2. 16\n",
       "3. 20\n",
       "4. 21\n",
       "5. 24\n",
       "6. 2\n",
       "7. 10\n",
       "8. 3\n",
       "9. 22\n",
       "10. 8\n",
       "11. 19\n",
       "12. 6\n",
       "13. 4\n",
       "14. 14\n",
       "15. 15\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  9 16 20 21 24  2 10  3 22  8 19  6  4 14 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.all <- data.frame(midterm1 = midterm1, gender = gender, aam = aam)\n",
    "random.index <- sample(1 : 24, 15, replace = FALSE)\n",
    "random.index\n",
    "data.train <- data.all[random.index, ]\n",
    "data.test <- data.all[-random.index, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"sample\" above draws 15 random numbers from integers between 1 and 24 without sampling any number twice (replace = FALSE). These 15 random numbers are saved in \"random.index\". Note that \"data.all[random.index, ]\" makes a sub-dataset of the observations corresponding to \"random.index\", and \"data.all[-random.index, ]\" makes a sub-dataset of the observations NOT corresponding to \"random.index\" (i.e., a complement set).\n",
    "\n",
    "Then, the code below fits the  neural network model and saves the fits in the object \"res\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res <- neuralnet(aam ~ midterm1 + gender, data = data.train, \n",
    "                hidden = c(3, 2), act.fct = \"logistic\", linear.output = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument \"hidden = c(3, 2)\" means that there are two layers, the first of which has three nodes and the second has two nodes. If \"linear.output = TRUE\", then the identity function is used regardless of the specified activation function (\"act.fct = logistic\").\n",
    "\n",
    "We can simply visualize the fits using the \"plot\" function and display all of the details using the function \"print\" below. For some reason, the plot does not work in Jupyter notebook, although this code will work on your local R console. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$call\n",
      "neuralnet(formula = aam ~ midterm1 + gender, data = data.train, \n",
      "    hidden = c(3, 2), act.fct = \"logistic\", linear.output = FALSE)\n",
      "\n",
      "$response\n",
      "   aam\n",
      "9    0\n",
      "16   1\n",
      "20   0\n",
      "21   0\n",
      "24   0\n",
      "2    1\n",
      "10   0\n",
      "3    1\n",
      "22   1\n",
      "8    1\n",
      "19   0\n",
      "6    1\n",
      "4    0\n",
      "14   0\n",
      "15   1\n",
      "\n",
      "$covariate\n",
      "   midterm1 gender\n",
      "9     18.00      0\n",
      "16    20.00      0\n",
      "20    18.00      0\n",
      "21    16.00      0\n",
      "24    19.50      1\n",
      "2     22.50      0\n",
      "10    18.00      0\n",
      "3     21.50      0\n",
      "22    21.85      1\n",
      "8     20.00      1\n",
      "19    18.50      1\n",
      "6     25.00      0\n",
      "4     21.25      0\n",
      "14    19.00      0\n",
      "15    24.00      1\n",
      "\n",
      "$model.list\n",
      "$model.list$response\n",
      "[1] \"aam\"\n",
      "\n",
      "$model.list$variables\n",
      "[1] \"midterm1\" \"gender\"  \n",
      "\n",
      "\n",
      "$err.fct\n",
      "function (x, y) \n",
      "{\n",
      "    1/2 * (y - x)^2\n",
      "}\n",
      "<bytecode: 0x7f83726a9858>\n",
      "<environment: 0x7f83726adad0>\n",
      "attr(,\"type\")\n",
      "[1] \"sse\"\n",
      "\n",
      "$act.fct\n",
      "function (x) \n",
      "{\n",
      "    1/(1 + exp(-x))\n",
      "}\n",
      "<bytecode: 0x7f83726d3e08>\n",
      "<environment: 0x7f83726c4d78>\n",
      "attr(,\"type\")\n",
      "[1] \"logistic\"\n",
      "\n",
      "$linear.output\n",
      "[1] FALSE\n",
      "\n",
      "$data\n",
      "   midterm1 gender aam\n",
      "9     18.00      0   0\n",
      "16    20.00      0   1\n",
      "20    18.00      0   0\n",
      "21    16.00      0   0\n",
      "24    19.50      1   0\n",
      "2     22.50      0   1\n",
      "10    18.00      0   0\n",
      "3     21.50      0   1\n",
      "22    21.85      1   1\n",
      "8     20.00      1   1\n",
      "19    18.50      1   0\n",
      "6     25.00      0   1\n",
      "4     21.25      0   0\n",
      "14    19.00      0   0\n",
      "15    24.00      1   1\n",
      "\n",
      "$exclude\n",
      "NULL\n",
      "\n",
      "$net.result\n",
      "$net.result[[1]]\n",
      "           [,1]\n",
      "9  9.540814e-10\n",
      "16 6.381972e-01\n",
      "20 9.540814e-10\n",
      "21 5.943569e-10\n",
      "24 1.072213e-02\n",
      "2  9.860130e-01\n",
      "10 9.540814e-10\n",
      "3  6.937107e-01\n",
      "22 1.000000e+00\n",
      "8  9.868395e-01\n",
      "19 2.092683e-09\n",
      "6  1.000000e+00\n",
      "4  6.679561e-01\n",
      "14 2.682283e-02\n",
      "15 1.000000e+00\n",
      "\n",
      "\n",
      "$weights\n",
      "$weights[[1]]\n",
      "$weights[[1]][[1]]\n",
      "           [,1]       [,2]     [,3]\n",
      "[1,]  2.0207058 -2.5304823 2.007788\n",
      "[2,] -0.1247692  0.1395073 2.232168\n",
      "[3,] -0.9841557 -1.2342949 1.993695\n",
      "\n",
      "$weights[[1]][[2]]\n",
      "            [,1]       [,2]\n",
      "[1,]   0.1212963  -3.063802\n",
      "[2,] -88.3673811  79.274039\n",
      "[3,]  73.1764639 -25.103926\n",
      "[4,]  -0.9345088  -3.978987\n",
      "\n",
      "$weights[[1]][[3]]\n",
      "           [,1]\n",
      "[1,]  -1.092995\n",
      "[2,]  21.838440\n",
      "[3,] -20.150559\n",
      "\n",
      "\n",
      "\n",
      "$generalized.weights\n",
      "$generalized.weights[[1]]\n",
      "           [,1]          [,2]\n",
      "9  2.441834e+00 -5.137372e-01\n",
      "16 1.568189e-01 -2.588936e-02\n",
      "20 2.441834e+00 -5.137372e-01\n",
      "21 6.616479e-05 -4.319618e-06\n",
      "24 2.221378e+01 -5.077132e+00\n",
      "2  8.764507e+00  2.906316e+01\n",
      "10 2.441834e+00 -5.137372e-01\n",
      "3  6.716037e-01  2.241487e+00\n",
      "22 2.020033e+00  3.317623e+00\n",
      "8  1.400730e+01  1.577731e+01\n",
      "19 4.164228e+00  5.212249e-01\n",
      "6  2.394327e-01  7.882829e-01\n",
      "4  3.190942e-01  1.066230e+00\n",
      "14 1.765245e+01 -4.768088e+00\n",
      "15 2.837274e-02  1.538695e-02\n",
      "\n",
      "\n",
      "$startweights\n",
      "$startweights[[1]]\n",
      "$startweights[[1]][[1]]\n",
      "            [,1]        [,2]       [,3]\n",
      "[1,]  0.66716492 0.006214183 -0.2730893\n",
      "[2,]  0.03084032 0.420400522 -0.5046316\n",
      "[3,] -0.40012373 0.999578446 -0.6747046\n",
      "\n",
      "$startweights[[1]][[2]]\n",
      "           [,1]       [,2]\n",
      "[1,] -0.8366665  0.2591530\n",
      "[2,]  0.8233589  2.0147868\n",
      "[3,]  0.6292197  1.1348055\n",
      "[4,] -1.8924716 -0.6560323\n",
      "\n",
      "$startweights[[1]][[3]]\n",
      "            [,1]\n",
      "[1,] -2.57071384\n",
      "[2,] -0.09918179\n",
      "[3,] -3.07270380\n",
      "\n",
      "\n",
      "\n",
      "$result.matrix\n",
      "                               [,1]\n",
      "error                  3.360415e-01\n",
      "reached.threshold      8.435521e-03\n",
      "steps                  8.200000e+03\n",
      "Intercept.to.1layhid1  2.020706e+00\n",
      "midterm1.to.1layhid1  -1.247692e-01\n",
      "gender.to.1layhid1    -9.841557e-01\n",
      "Intercept.to.1layhid2 -2.530482e+00\n",
      "midterm1.to.1layhid2   1.395073e-01\n",
      "gender.to.1layhid2    -1.234295e+00\n",
      "Intercept.to.1layhid3  2.007788e+00\n",
      "midterm1.to.1layhid3   2.232168e+00\n",
      "gender.to.1layhid3     1.993695e+00\n",
      "Intercept.to.2layhid1  1.212963e-01\n",
      "1layhid1.to.2layhid1  -8.836738e+01\n",
      "1layhid2.to.2layhid1   7.317646e+01\n",
      "1layhid3.to.2layhid1  -9.345088e-01\n",
      "Intercept.to.2layhid2 -3.063802e+00\n",
      "1layhid1.to.2layhid2   7.927404e+01\n",
      "1layhid2.to.2layhid2  -2.510393e+01\n",
      "1layhid3.to.2layhid2  -3.978987e+00\n",
      "Intercept.to.aam      -1.092995e+00\n",
      "2layhid1.to.aam        2.183844e+01\n",
      "2layhid2.to.aam       -2.015056e+01\n",
      "\n",
      "attr(,\"class\")\n",
      "[1] \"nn\"\n"
     ]
    }
   ],
   "source": [
    "plot(res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making predictions\n",
    "\n",
    "Finally, let's make predictions using the test set and calculate the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.222"
      ],
      "text/latex": [
       "0.222"
      ],
      "text/markdown": [
       "0.222"
      ],
      "text/plain": [
       "[1] 0.222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred.temp <- compute(res, data.test)\n",
    "est.prob <- pred.temp$net.result\n",
    "pred <- ifelse(est.prob > 0.5, 1, 0)\n",
    "mse <- mean((data.test$aam - pred)^2)\n",
    "round(mse, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
